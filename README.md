<div class="Box-sc-g0xbh4-0 QkQOb js-snippet-clipboard-copy-unpositioned" data-hpc="true"><article class="markdown-body entry-content container-lg" itemprop="text"><div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="74103328" _msthash="199">Flickr-Faces-HQ 数据集 （FFHQ）</h2><a id="user-content-flickr-faces-hq-dataset-ffhq" class="anchor" aria-label="永久链接： flickr-faces-HQ 数据集 （FFHQ）" href="#flickr-faces-hq-dataset-ffhq" _mstaria-label="1083264" _msthash="200"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c975474b499ca134165b3d0851e58c36924fc9fc11448732682ca6e8f2073c02/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963"><img src="https://camo.githubusercontent.com/c975474b499ca134165b3d0851e58c36924fc9fc11448732682ca6e8f2073c02/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963" alt="Python 3.6 版" data-canonical-src="https://img.shields.io/badge/python-3.6-green.svg?style=plastic" style="max-width: 100%;" _mstalt="107510" _msthash="201"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/83e95597623e70e6638661ec43195dfbcf8071ced474f24715566d815568289a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d43432d677265656e2e7376673f7374796c653d706c6173746963"><img src="https://camo.githubusercontent.com/83e95597623e70e6638661ec43195dfbcf8071ced474f24715566d815568289a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d43432d677265656e2e7376673f7374796c653d706c6173746963" alt="许可证 CC" data-canonical-src="https://img.shields.io/badge/license-CC-green.svg?style=plastic" style="max-width: 100%;" _mstalt="118547" _msthash="202"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8e1f9ca0292dd8cf45ec6ec8a08f69d7c26c911facb9a6d87216b82ea240a196/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666f726d61742d504e472d677265656e2e7376673f7374796c653d706c6173746963"><img src="https://camo.githubusercontent.com/8e1f9ca0292dd8cf45ec6ec8a08f69d7c26c911facb9a6d87216b82ea240a196/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666f726d61742d504e472d677265656e2e7376673f7374796c653d706c6173746963" alt="设置 PNG 格式" data-canonical-src="https://img.shields.io/badge/format-PNG-green.svg?style=plastic" style="max-width: 100%;" _mstalt="118950" _msthash="203"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/ada4eeda0db59847a313ca2bd483de9d0f4c4f79288bb4f31395ded8d815d077/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7265736f6c7574696f6e2d31303234254333253937313032342d677265656e2e7376673f7374796c653d706c6173746963"><img src="https://camo.githubusercontent.com/ada4eeda0db59847a313ca2bd483de9d0f4c4f79288bb4f31395ded8d815d077/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7265736f6c7574696f6e2d31303234254333253937313032342d677265656e2e7376673f7374796c653d706c6173746963" alt="分辨率 1024×1024" data-canonical-src="https://img.shields.io/badge/resolution-1024%C3%971024-green.svg?style=plastic" style="max-width: 100%;" _mstalt="330278" _msthash="204"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a1b988bb821372f507ebd74a4a8ebd067a9393d6cce2a1287339eddeed758b74/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696d616765732d37302c3030302d677265656e2e7376673f7374796c653d706c6173746963"><img src="https://camo.githubusercontent.com/a1b988bb821372f507ebd74a4a8ebd067a9393d6cce2a1287339eddeed758b74/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696d616765732d37302c3030302d677265656e2e7376673f7374796c653d706c6173746963" alt="图片 70000" data-canonical-src="https://img.shields.io/badge/images-70,000-green.svg?style=plastic" style="max-width: 100%;" _mstalt="123084" _msthash="205"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="/NVlabs/ffhq-dataset/blob/master/ffhq-teaser.png"><img src="/NVlabs/ffhq-dataset/raw/master/ffhq-teaser.png" alt="Teaser 图片" style="max-width: 100%;" _mstalt="176917" _msthash="206"></a></p>
<p dir="auto" _msttexthash="702945048" _msthash="207">Flickr-Faces-HQ （FFHQ） 是一个高质量的人脸图像数据集，最初是作为生成对抗网络 （GAN） 的基准创建的：</p>
<blockquote>
<p dir="auto" _msttexthash="425524411" _msthash="208"><strong _istranslated="1">用于生成对抗网络</strong><br _istranslated="1">的基于样式的生成器架构Tero Karras （NVIDIA）、Samuli Laine （NVIDIA）、Timo Aila （NVIDIA）<br _istranslated="1"> <a href="https://arxiv.org/abs/1812.04948" rel="nofollow" _istranslated="1">https://arxiv.org/abs/1812.04948</a></p>
</blockquote>
<p dir="auto" _msttexthash="5525350220" _msthash="209">该数据集由 70,000 张分辨率为 1024×1024 的高质量 PNG 图像组成，在年龄、种族和图像背景方面存在相当大的差异。它还对眼镜、太阳镜、帽子等配饰有很好的覆盖。这些图片是从 <a href="https://www.flickr.com/" rel="nofollow" _istranslated="1">Flickr</a> 爬取的，因此继承了该网站的所有偏见，并使用 <a href="http://dlib.net/" rel="nofollow" _istranslated="1">dlib</a> 自动对齐和裁剪。仅收集 permissive licenses 下的映像。使用了各种自动过滤器来修剪布景，最后使用 <a href="https://www.mturk.com/" rel="nofollow" _istranslated="1">Amazon Mechanical Turk</a> 去除偶尔出现的雕像、绘画或照片照片。</p>
<p dir="auto" _msttexthash="690382927" _msthash="210">请注意，此数据集不适用于也不应用于面部识别技术的开发或改进。有关业务咨询，请访问我们的网站并提交表格：<a href="https://www.nvidia.com/en-us/research/inquiries/" rel="nofollow" _istranslated="1">NVIDIA Research 许可</a></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="9675445" _msthash="211">许可证</h2><a id="user-content-licenses" class="anchor" aria-label="永久链接： 许可证" href="#licenses" _mstaria-label="367783" _msthash="212"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="5524553333" _msthash="213">每张图片由各自的作者根据 <a href="https://creativecommons.org/licenses/by/2.0/" rel="nofollow" _istranslated="1">Creative Commons BY 2.0</a>、<a href="https://creativecommons.org/licenses/by-nc/2.0/" rel="nofollow" _istranslated="1">Creative Commons BY-NC 2.0</a>、<a href="https://creativecommons.org/publicdomain/mark/1.0/" rel="nofollow" _istranslated="1">Public Domain Mark 1.0</a>、<a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow" _istranslated="1">Public Domain CC0 1.0</a> 或 <a href="http://www.usa.gov/copyright.shtml" rel="nofollow" _istranslated="1">U.S. Government Works</a> 许可在 Flickr 上发布。所有这些许可证都允许<strong _istranslated="1">出于非商业目的免费使用、重新分发和改编</strong>。但是，其中一些需要对原作者给予<strong _istranslated="1">适当的信任</strong>，并指出对图像所做的<strong _istranslated="1">任何更改</strong>。元数据中指示了每个图像的许可证和原始作者。</p>
<ul dir="auto">
<li><a href="https://creativecommons.org/licenses/by/2.0/" rel="nofollow" _msttexthash="1460238" _msthash="214">https://creativecommons.org/licenses/by/2.0/</a></li>
<li><a href="https://creativecommons.org/licenses/by-nc/2.0/" rel="nofollow" _msttexthash="1625416" _msthash="215">https://creativecommons.org/licenses/by-nc/2.0/</a></li>
<li><a href="https://creativecommons.org/publicdomain/mark/1.0/" rel="nofollow" _msttexthash="1869023" _msthash="216">https://creativecommons.org/publicdomain/mark/1.0/</a></li>
<li><a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow" _msttexthash="1882335" _msthash="217">https://creativecommons.org/publicdomain/zero/1.0/</a></li>
<li><a href="http://www.usa.gov/copyright.shtml" rel="nofollow" _msttexthash="1039129" _msthash="218">http://www.usa.gov/copyright.shtml</a></li>
</ul>
<p dir="auto" _msttexthash="3970629117" _msthash="219">数据集本身（包括 JSON 元数据、下载脚本和文档）由 NVIDIA Corporation 根据 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="nofollow" _istranslated="1">Creative Commons BY-NC-SA 4.0</a> 许可提供。您可以<strong _istranslated="1">出于非商业目的使用、重新分发和改编它</strong>，只要您 （a） 通过<strong _istranslated="1">引用我们的论文</strong>给予适当的信任，（b） 表明您所做的<strong _istranslated="1">任何更改</strong>，以及 （c） 在同一<strong _istranslated="1">许可证下</strong>分发任何衍生作品。</p>
<ul dir="auto">
<li><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="nofollow" _msttexthash="1803802" _msthash="220">https://creativecommons.org/licenses/by-nc-sa/4.0/</a></li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="6290102" _msthash="221">概述</h2><a id="user-content-overview" class="anchor" aria-label="永久链接： 概述" href="#overview" _mstaria-label="375934" _msthash="222"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="59989644" _msthash="223">所有数据都托管在 Google Drive 上：</p>
<markdown-accessiblity-table data-catalyst=""><table>
<thead>
<tr>
<th align="left" _msttexthash="5849493" _msthash="224">路径</th>
<th align="center" _msttexthash="4527861" _msthash="225">大小</th>
<th align="right" _msttexthash="4467437" _msthash="226">文件</th>
<th align="center" _msttexthash="4959084" _msthash="227">格式</th>
<th align="left" _msttexthash="6157333" _msthash="228">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><a href="https://drive.google.com/open?id=1u2xu7bSrWxrbUxk-dT-UvEJq8IjdmNTP" rel="nofollow" _msttexthash="14254058" _msthash="229">ffhq 数据集</a></td>
<td align="center" _msttexthash="13922597" _msthash="230">2.56结核病</td>
<td align="right" _msttexthash="44278" _msthash="231">210,014</td>
<td align="center"></td>
<td align="left" _msttexthash="9859889" _msthash="232">主文件夹</td>
</tr>
<tr>
<td align="left" _msttexthash="1297335" _msthash="233">├&nbsp; <a href="https://drive.google.com/open?id=16N0RV4fHI6joBuKbQAoG34V_cQk7vxSA" rel="nofollow">ffhq-dataset-v2.json</a></td>
<td align="center" _msttexthash="11276772" _msthash="234">255 兆字节</td>
<td align="right" _msttexthash="4459" _msthash="235">1</td>
<td align="center" _msttexthash="7646821" _msthash="236">JSON 格式</td>
<td align="left" _msttexthash="56834297" _msthash="237">元数据，包括版权信息、URL 等。</td>
</tr>
<tr>
<td align="left" _msttexthash="6697834" _msthash="238">├ <a href="https://drive.google.com/open?id=1tZUcXDBeOibC6jcMCtgRRz67pzrAHeHL" rel="nofollow" _istranslated="1">图片1024x1024</a></td>
<td align="center" _msttexthash="12393173" _msthash="239">89.1 吉字节</td>
<td align="right" _msttexthash="35737" _msthash="240">70,000</td>
<td align="center" _msttexthash="23699" _msthash="241">PNG</td>
<td align="left" _msttexthash="66707589" _msthash="242">在 1024×1024 处对齐和裁剪的图像</td>
</tr>
<tr>
<td align="left" _msttexthash="10739755" _msthash="243">├ <a href="https://drive.google.com/open?id=1tg-Ur7d4vk1T8Bn0pPpUSQPxlPGBlGfv" rel="nofollow" _istranslated="1">缩略图128x128</a></td>
<td align="center" _msttexthash="12393199" _msthash="244">1.95 吉字节</td>
<td align="right" _msttexthash="35737" _msthash="245">70,000</td>
<td align="center" _msttexthash="23699" _msthash="246">PNG</td>
<td align="left" _msttexthash="28756065" _msthash="247">128×128 处的缩略图</td>
</tr>
<tr>
<td align="left" _msttexthash="21825713" _msthash="248">├ <a href="https://drive.google.com/open?id=1ZX7QOy6LZuTLTnsOtQk-kmKq2-69l5hu" rel="nofollow" _istranslated="1">在野外的图像</a></td>
<td align="center" _msttexthash="11369319" _msthash="249">955 吉字节</td>
<td align="right" _msttexthash="35737" _msthash="250">70,000</td>
<td align="center" _msttexthash="23699" _msthash="251">PNG</td>
<td align="left" _msttexthash="31728983" _msthash="252">来自 Flickr 的原始图像</td>
</tr>
<tr>
<td align="left" _msttexthash="1009060" _msthash="253">├ <a href="https://drive.google.com/open?id=1LTBpJ0W_WLjqza3zdayligS8Dh1V1gA6" rel="nofollow" _istranslated="1">TFrecords</a></td>
<td align="center" _msttexthash="11368656" _msthash="254">273 吉字节</td>
<td align="right" _msttexthash="5187" _msthash="255">9</td>
<td align="center" _msttexthash="138996" _msthash="256">tfrecords</td>
<td align="left" _msttexthash="74382438" _msthash="257"><a href="https://github.com/NVlabs/stylegan" _istranslated="1">StyleGAN</a> 和 <a href="https://github.com/NVlabs/stylegan2" _istranslated="1">StyleGAN2</a> 的多分辨率数据</td>
</tr>
<tr>
<td align="left" _msttexthash="7956442" _msthash="258">└ <a href="https://drive.google.com/open?id=1WocxvZ4GEZ1DI8dOz30aSj2zT6pkATYS" rel="nofollow" _istranslated="1">拉链</a></td>
<td align="center" _msttexthash="13922415" _msthash="259">1.28 结核病</td>
<td align="right" _msttexthash="4732" _msthash="260">4</td>
<td align="center" _msttexthash="6753994" _msthash="261">邮编</td>
<td align="left" _msttexthash="51134941" _msthash="262">每个文件夹的内容作为 ZIP 存档。</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto" _msttexthash="34147087" _msthash="263">高级统计数据：</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="/NVlabs/ffhq-dataset/blob/master/ffhq-piecharts.png"><img src="/NVlabs/ffhq-dataset/raw/master/ffhq-piecharts.png" alt="饼图" style="max-width: 100%;" _mstalt="135694" _msthash="264"></a></p>
<p dir="auto" _msttexthash="1185518620" _msthash="265">对于需要单独训练集和验证集的使用案例，我们已指定前 60000 张图像用于训练，其余 10000 张图像用于验证。然而，在 <a href="https://arxiv.org/abs/1812.04948" rel="nofollow" _istranslated="1">StyleGAN 论文</a>中，我们使用了所有 70,000 张图像进行训练。</p>
<p dir="auto"><font _mstmutation="1" _msttexthash="973364106" _msthash="266">我们已明确确保数据集本身中没有重复的图像。但是，请注意，如果我们从同一张图像中提取了多张不同的面孔，则该文件夹可能包含同一张图片的多个副本。</font><code>in-the-wild</code></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="12938731" _msthash="267">下载脚本</h2><a id="user-content-download-script" class="anchor" aria-label="永久链接： 下载脚本" href="#download-script" _mstaria-label="603668" _msthash="268"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="1764501479" _msthash="269">您可以直接从 Google Drive 获取数据，也可以使用提供的<a href="/NVlabs/ffhq-dataset/blob/master/download_ffhq.py" _istranslated="1">下载脚本</a>。该脚本通过自动下载所有请求的文件、验证其校验和、出错时多次重试每个文件以及使用多个并发连接来最大化带宽，使事情变得相当容易。</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto"><pre class="notranslate"><code>&gt; python download_ffhq.py -h
usage: download_ffhq.py [-h] [-j] [-s] [-i] [-t] [-w] [-r] [-a]
                        [--num_threads NUM] [--status_delay SEC]
                        [--timing_window LEN] [--chunk_size KB]
                        [--num_attempts NUM]

Download Flickr-Face-HQ (FFHQ) dataset to current working directory.

optional arguments:
  -h, --help            show this help message and exit
  -j, --json            download metadata as JSON (254 MB)
  -s, --stats           print statistics about the dataset
  -i, --images          download 1024x1024 images as PNG (89.1 GB)
  -t, --thumbs          download 128x128 thumbnails as PNG (1.95 GB)
  -w, --wilds           download in-the-wild images as PNG (955 GB)
  -r, --tfrecords       download multi-resolution TFRecords (273 GB)
  -a, --align           recreate 1024x1024 images from in-the-wild images
  --num_threads NUM     number of concurrent download threads (default: 32)
  --status_delay SEC    time between download status prints (default: 0.2)
  --timing_window LEN   samples for estimating download eta (default: 50)
  --chunk_size KB       chunk size for each download thread (default: 128)
  --num_attempts NUM    number of download attempts per file (default: 10)
  --random-shift SHIFT  standard deviation of random crop rectangle jitter
  --retry-crops         retry random shift if crop rectangle falls outside image (up to 1000
                        times)
  --no-rotation         keep the original orientation of images
  --no-padding          do not apply blur-padding outside and near the image borders
  --source-dir DIR      where to find already downloaded FFHQ source data
</code></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="> python download_ffhq.py -h
usage: download_ffhq.py [-h] [-j] [-s] [-i] [-t] [-w] [-r] [-a]
                        [--num_threads NUM] [--status_delay SEC]
                        [--timing_window LEN] [--chunk_size KB]
                        [--num_attempts NUM]

Download Flickr-Face-HQ (FFHQ) dataset to current working directory.

optional arguments:
  -h, --help            show this help message and exit
  -j, --json            download metadata as JSON (254 MB)
  -s, --stats           print statistics about the dataset
  -i, --images          download 1024x1024 images as PNG (89.1 GB)
  -t, --thumbs          download 128x128 thumbnails as PNG (1.95 GB)
  -w, --wilds           download in-the-wild images as PNG (955 GB)
  -r, --tfrecords       download multi-resolution TFRecords (273 GB)
  -a, --align           recreate 1024x1024 images from in-the-wild images
  --num_threads NUM     number of concurrent download threads (default: 32)
  --status_delay SEC    time between download status prints (default: 0.2)
  --timing_window LEN   samples for estimating download eta (default: 50)
  --chunk_size KB       chunk size for each download thread (default: 128)
  --num_attempts NUM    number of download attempts per file (default: 10)
  --random-shift SHIFT  standard deviation of random crop rectangle jitter
  --retry-crops         retry random shift if crop rectangle falls outside image (up to 1000
                        times)
  --no-rotation         keep the original orientation of images
  --no-padding          do not apply blur-padding outside and near the image borders
  --source-dir DIR      where to find already downloaded FFHQ source data" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto"><pre class="notranslate"><code>&gt; python ..\download_ffhq.py --json --images
Downloading JSON metadata...
\ 100.00% done  2/2 files  0.25/0.25 GB   43.21 MB/s  ETA: done
Parsing JSON metadata...
Downloading 70000 files...
| 100.00% done  70001/70001 files  89.19 GB/89.19 GB  59.87 MB/s  ETA: done
</code></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="> python ..\download_ffhq.py --json --images
Downloading JSON metadata...
\ 100.00% done  2/2 files  0.25/0.25 GB   43.21 MB/s  ETA: done
Parsing JSON metadata...
Downloading 70000 files...
| 100.00% done  70001/70001 files  89.19 GB/89.19 GB  59.87 MB/s  ETA: done" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="46829029" _msthash="270">The script also serves as a reference implementation of the automated scheme that we used to align and crop the images. Once you have downloaded the in-the-wild images with , you can run  to reproduce exact replicas of the aligned 1024×1024 images using the facial landmark locations included in the metadata.</font><code>python download_ffhq.py --wilds</code><code>python download_ffhq.py --align</code></p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="688688" _msthash="271">Reproducing the unaligned FFHQ</h3><a id="user-content-reproducing-the-unaligned-ffhq" class="anchor" aria-label="Permalink: Reproducing the unaligned FFHQ" href="#reproducing-the-unaligned-ffhq" _mstaria-label="1188863" _msthash="272"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="9870562" _msthash="273">To reproduce the "unaligned FFHQ" dataset as used in the <a href="https://arxiv.org/abs/2106.12423" rel="nofollow">Alias-Free Generative Adversarial Networks</a> paper, use the following options:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto"><pre class="notranslate"><code>python download_ffhq.py \
    --source-dir &lt;path/to/downloaded/ffhq&gt; \
    --align --no-rotation --random-shift 0.2 --no-padding --retry-crops
</code></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="python download_ffhq.py \
    --source-dir <path/to/downloaded/ffhq> \
    --align --no-rotation --random-shift 0.2 --no-padding --retry-crops" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="110383" _msthash="274">Metadata</h2><a id="user-content-metadata" class="anchor" aria-label="Permalink: Metadata" href="#metadata" _mstaria-label="361218" _msthash="275"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="4522973" _msthash="276">The  file contains the following information for each image in a machine-readable format:</font><code>ffhq-dataset-v2.json</code></p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto"><pre class="notranslate"><code>{
  "0": {                                                 # Image index
    "category": "training",                              # Training or validation
    "metadata": {                                        # Info about the original Flickr photo:
      "photo_url": "https://www.flickr.com/photos/...",  # - Flickr URL
      "photo_title": "DSCF0899.JPG",                     # - File name
      "author": "Jeremy Frumkin",                        # - Author
      "country": "",                                     # - Country where the photo was taken
      "license": "Attribution-NonCommercial License",    # - License name
      "license_url": "https://creativecommons.org/...",  # - License detail URL
      "date_uploaded": "2007-08-16",                     # - Date when the photo was uploaded to Flickr
      "date_crawled": "2018-10-10"                       # - Date when the photo was crawled from Flickr
    },
    "image": {                                           # Info about the aligned 1024x1024 image:
      "file_url": "https://drive.google.com/...",        # - Google Drive URL
      "file_path": "images1024x1024/00000/00000.png",    # - Google Drive path
      "file_size": 1488194,                              # - Size of the PNG file in bytes
      "file_md5": "ddeaeea6ce59569643715759d537fd1b",    # - MD5 checksum of the PNG file
      "pixel_size": [1024, 1024],                        # - Image dimensions
      "pixel_md5": "47238b44dfb87644460cbdcc4607e289",   # - MD5 checksum of the raw pixel data
      "face_landmarks": [...]                            # - 68 face landmarks reported by dlib
    },
    "thumbnail": {                                       # Info about the 128x128 thumbnail:
      "file_url": "https://drive.google.com/...",        # - Google Drive URL
      "file_path": "thumbnails128x128/00000/00000.png",  # - Google Drive path
      "file_size": 29050,                                # - Size of the PNG file in bytes
      "file_md5": "bd3e40b2ba20f76b55dc282907b89cd1",    # - MD5 checksum of the PNG file
      "pixel_size": [128, 128],                          # - Image dimensions
      "pixel_md5": "38d7e93eb9a796d0e65f8c64de8ba161"    # - MD5 checksum of the raw pixel data
    },
    "in_the_wild": {                                     # Info about the in-the-wild image:
      "file_url": "https://drive.google.com/...",        # - Google Drive URL
      "file_path": "in-the-wild-images/00000/00000.png", # - Google Drive path
      "file_size": 3991569,                              # - Size of the PNG file in bytes
      "file_md5": "1dc0287e73e485efb0516a80ce9d42b4",    # - MD5 checksum of the PNG file
      "pixel_size": [2016, 1512],                        # - Image dimensions
      "pixel_md5": "86b3470c42e33235d76b979161fb2327",   # - MD5 checksum of the raw pixel data
      "face_rect": [667, 410, 1438, 1181],               # - Axis-aligned rectangle of the face region
      "face_landmarks": [...],                           # - 68 face landmarks reported by dlib
      "face_quad": [...]                                 # - Aligned quad of the face region
    }
  },
  ...
}
</code></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="{
  &quot;0&quot;: {                                                 # Image index
    &quot;category&quot;: &quot;training&quot;,                              # Training or validation
    &quot;metadata&quot;: {                                        # Info about the original Flickr photo:
      &quot;photo_url&quot;: &quot;https://www.flickr.com/photos/...&quot;,  # - Flickr URL
      &quot;photo_title&quot;: &quot;DSCF0899.JPG&quot;,                     # - File name
      &quot;author&quot;: &quot;Jeremy Frumkin&quot;,                        # - Author
      &quot;country&quot;: &quot;&quot;,                                     # - Country where the photo was taken
      &quot;license&quot;: &quot;Attribution-NonCommercial License&quot;,    # - License name
      &quot;license_url&quot;: &quot;https://creativecommons.org/...&quot;,  # - License detail URL
      &quot;date_uploaded&quot;: &quot;2007-08-16&quot;,                     # - Date when the photo was uploaded to Flickr
      &quot;date_crawled&quot;: &quot;2018-10-10&quot;                       # - Date when the photo was crawled from Flickr
    },
    &quot;image&quot;: {                                           # Info about the aligned 1024x1024 image:
      &quot;file_url&quot;: &quot;https://drive.google.com/...&quot;,        # - Google Drive URL
      &quot;file_path&quot;: &quot;images1024x1024/00000/00000.png&quot;,    # - Google Drive path
      &quot;file_size&quot;: 1488194,                              # - Size of the PNG file in bytes
      &quot;file_md5&quot;: &quot;ddeaeea6ce59569643715759d537fd1b&quot;,    # - MD5 checksum of the PNG file
      &quot;pixel_size&quot;: [1024, 1024],                        # - Image dimensions
      &quot;pixel_md5&quot;: &quot;47238b44dfb87644460cbdcc4607e289&quot;,   # - MD5 checksum of the raw pixel data
      &quot;face_landmarks&quot;: [...]                            # - 68 face landmarks reported by dlib
    },
    &quot;thumbnail&quot;: {                                       # Info about the 128x128 thumbnail:
      &quot;file_url&quot;: &quot;https://drive.google.com/...&quot;,        # - Google Drive URL
      &quot;file_path&quot;: &quot;thumbnails128x128/00000/00000.png&quot;,  # - Google Drive path
      &quot;file_size&quot;: 29050,                                # - Size of the PNG file in bytes
      &quot;file_md5&quot;: &quot;bd3e40b2ba20f76b55dc282907b89cd1&quot;,    # - MD5 checksum of the PNG file
      &quot;pixel_size&quot;: [128, 128],                          # - Image dimensions
      &quot;pixel_md5&quot;: &quot;38d7e93eb9a796d0e65f8c64de8ba161&quot;    # - MD5 checksum of the raw pixel data
    },
    &quot;in_the_wild&quot;: {                                     # Info about the in-the-wild image:
      &quot;file_url&quot;: &quot;https://drive.google.com/...&quot;,        # - Google Drive URL
      &quot;file_path&quot;: &quot;in-the-wild-images/00000/00000.png&quot;, # - Google Drive path
      &quot;file_size&quot;: 3991569,                              # - Size of the PNG file in bytes
      &quot;file_md5&quot;: &quot;1dc0287e73e485efb0516a80ce9d42b4&quot;,    # - MD5 checksum of the PNG file
      &quot;pixel_size&quot;: [2016, 1512],                        # - Image dimensions
      &quot;pixel_md5&quot;: &quot;86b3470c42e33235d76b979161fb2327&quot;,   # - MD5 checksum of the raw pixel data
      &quot;face_rect&quot;: [667, 410, 1438, 1181],               # - Axis-aligned rectangle of the face region
      &quot;face_landmarks&quot;: [...],                           # - 68 face landmarks reported by dlib
      &quot;face_quad&quot;: [...]                                 # - Aligned quad of the face region
    }
  },
  ...
}" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="320957" _msthash="277">Acknowledgements</h2><a id="user-content-acknowledgements" class="anchor" aria-label="Permalink: Acknowledgements" href="#acknowledgements" _mstaria-label="685412" _msthash="278"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="25601524" _msthash="279">We thank Jaakko Lehtinen, David Luebke, and Tuomas Kynkäänniemi for in-depth discussions and helpful comments; Janne Hellsten, Tero Kuosmanen, and Pekka Jänis for compute infrastructure and help with the code release.</p>
<p dir="auto" _msttexthash="13706914" _msthash="280">We also thank Vahid Kazemi and Josephine Sullivan for their work on automatic face detection and alignment that enabled us to collect the data in the first place:</p>
<blockquote>
<p dir="auto" _msttexthash="29616236" _msthash="281"><strong>One Millisecond Face Alignment with an Ensemble of Regression Trees</strong><br>
Vahid Kazemi, Josephine Sullivan<br>
Proc. CVPR 2014<br>
<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kazemi_One_Millisecond_Face_2014_CVPR_paper.pdf" rel="nofollow">https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kazemi_One_Millisecond_Face_2014_CVPR_paper.pdf</a></p>
</blockquote>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="96525" _msthash="282">Privacy</h2><a id="user-content-privacy" class="anchor" aria-label="Permalink: Privacy" href="#privacy" _mstaria-label="338650" _msthash="283"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="58695234" _msthash="284">When collecting the data, we were careful to only include photos that – to the best of our knowledge – were intended for free use and redistribution by their respective authors. That said, we are committed to protecting the privacy of individuals who do not wish their photos to be included.</p>
<p dir="auto" _msttexthash="11296142" _msthash="285">To find out whether your photo is included in the Flickr-Faces-HQ dataset, please <a href="https://nvlabs.github.io/ffhq-dataset/search/" rel="nofollow">click this link</a> to search the dataset with your Flickr username.</p>
<p dir="auto" _msttexthash="2086734" _msthash="286">To get your photo removed from the Flickr-Faces-HQ dataset:</p>
<ol dir="auto">
<li><font _mstmutation="1" _msttexthash="1026051" _msthash="287">Go to Flickr and do one of the following:
</font><ul dir="auto">
<li><font _mstmutation="1" _msttexthash="4823845" _msthash="288">Tag the photo with  to indicate that you do not wish it to be used for computer vision research.</font><code>no_cv</code></li>
<li><font _mstmutation="1" _msttexthash="11704433" _msthash="289">Change the license of the photo to  (All rights reserved) or any Creative Commons license with  to indicate that you do not want it to be redistributed.</font><code>None</code><code>NoDerivs</code></li>
<li _msttexthash="3182088" _msthash="290">Make the photo private, i.e., only visible to you and your friends/family.</li>
<li _msttexthash="1365676" _msthash="291">Get the photo removed from Flickr altogether.</li>
</ul>
</li>
<li _msttexthash="4743908" _msthash="292">Contact <a href="mailto:researchinquiries@nvidia.com">researchinquiries@nvidia.com</a>. Please include your Flickr username in the email.</li>
<li _msttexthash="5482815" _msthash="293">We will check the status of all photos from the particular user and update the dataset accordingly.</li>
</ol>
</article></div>
